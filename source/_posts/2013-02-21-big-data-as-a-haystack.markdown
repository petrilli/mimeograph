---
layout: post
title: "Big data as a haystack"
date: 2013-02-21 15:05
comments: true
categories: big-data
---

Yesterday's video by [James Governor](http://redmonk.com/jgovernor/2012/09/27/how-to-not-define-big-data/) about "how not to define big data" got me to thinking, as so much of James' writing does.
First, go watch the video:

<iframe width="560" height="315" src="http://www.youtube.com/embed/O1l0HiKY3tA?rel=0" frameborder="0" allowfullscreen></iframe>

People often talk about big data as though it is a measurable quantity, something quantitative.
And it is, but that's inadequate to understand the different nature of it.
For me, the more important aspect is qualitative.
Big data isn't just about the number of gigabytes that your system deals with, but instead about the underlying nature of that data.
Take, for example, traditional account data, where we might store orders, and shipping information. 
This data has a high signal-to-noise ratio.
If, instead, we look at things like website logs, telemetry from embedded devices, or even a stream of tweets, we're talking about what is traditionally a *very low* signal-to-noise ratio.

Big data, then, isn't just about the size of your haystack, but instead finding the needle hidden within.